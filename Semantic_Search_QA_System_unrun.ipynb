{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Search_QA_System_unrun.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp0uK1mafrAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw26sRfMlqB4",
        "colab_type": "text"
      },
      "source": [
        "Contents:\n",
        "\n",
        "Loading Required Libraries\n",
        "\n",
        "Loading Metadata Information\n",
        "\n",
        "Fetching all the JSON Files\n",
        "\n",
        "Helper Functions\n",
        "\n",
        "Data Pre-Processing/Cleaning\n",
        "\n",
        "Sentence Tokenization\n",
        "\n",
        "Loading Flair & Elmo Contextual Biomedical Embeddings\n",
        "\n",
        "Dimensionality Reduction with t-SNE\n",
        "\n",
        "Create Clusters (K-Means) of Sentence Embeddings\n",
        "\n",
        "Semantic Search\n",
        "\n",
        "An End-To-End Closed Domain Question Answering System (CdQA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKQ8xqezlwfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## General Utilities\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import glob\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "## Sklearn Utilities\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "## Tqdm Utilities\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "## Bokeh Utilities\n",
        "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper, CustomJS\n",
        "from bokeh.palettes import Category20\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.io import output_file, show\n",
        "from bokeh.transform import transform\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.layouts import column\n",
        "from bokeh.models import RadioButtonGroup\n",
        "from bokeh.models import TextInput\n",
        "from bokeh.layouts import gridplot\n",
        "from bokeh.models import Div\n",
        "from bokeh.models import Paragraph\n",
        "from bokeh.layouts import column, widgetbox\n",
        "\n",
        "## IPython Utilities\n",
        "from IPython.display import HTML\n",
        "\n",
        "import notebook as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, interactive_output, VBox\n",
        "\n",
        "from IPython.html import widgets\n",
        "from IPython.display import display, Image, HTML, Markdown, clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmjalrNol-wA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Install flair library\n",
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDmEqOUbl-1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Install allennlp library\n",
        "\n",
        "!pip install allennlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVByaTfml-45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoN4-HOOl-zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load Spacy Utilities:\n",
        "import spacy\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load()\n",
        "## Flair Utilities\n",
        "from flair.embeddings import ELMoEmbeddings, PooledFlairEmbeddings, Sentence, DocumentPoolEmbeddings\n",
        "from typing import List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSfq8miql-t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/kaggle/input/CORD-19-research-challenge/'\n",
        "metadata_path = f'{root_path}/metadata.csv'\n",
        "meta_df = pd.read_csv(metadata_path, dtype={\n",
        "    'pubmed_id': str,\n",
        "    'Microsoft Academic Paper ID': str, \n",
        "    'doi': str\n",
        "})\n",
        "meta_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa-gf1vkmYgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TZeMI9YmYkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fetching all the JSON files\n",
        "\n",
        "all_json = glob.glob(f'{root_path}/**/*.json', recursive=True)\n",
        "print(len(all_json))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PopG7ZV1mYe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Helper Functions\n",
        "\n",
        "def cstr(s, color='blue'):\n",
        "    return \"<text style=color:{}>{}</text>\".format(color, s)\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(cstr(string)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRC7ilfHmnSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## JSON File Reader Class\n",
        "class FileReader:\n",
        "    \"\"\"FileReader adds break after every words when character length reach to certain amount.\"\"\"\n",
        "    def __init__(self, file_path):\n",
        "        with open(file_path) as file:\n",
        "            content = json.load(file)\n",
        "            self.paper_id = content['paper_id']\n",
        "            self.abstract = []\n",
        "            self.body_text = []\n",
        "            # Abstract\n",
        "            for entry in content['abstract']:\n",
        "                self.abstract.append(entry['text'])\n",
        "            # Body text\n",
        "            for entry in content['body_text']:\n",
        "                self.body_text.append(entry['text'])\n",
        "            self.abstract = '\\n'.join(self.abstract)\n",
        "            self.body_text = '\\n'.join(self.body_text)\n",
        "    def __repr__(self):\n",
        "        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abs_TeVtmnY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_row = FileReader(all_json[0])\n",
        "print(first_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN2d_xX_mnV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_breaks(content, length):\n",
        "    data = \"\"\n",
        "    words = content.split(' ')\n",
        "    total_chars = 0\n",
        "\n",
        "    # add break every length characters\n",
        "    for i in range(len(words)):\n",
        "        total_chars += len(words[i])\n",
        "        if total_chars > length:\n",
        "            data = data + \"<br>\" + words[i]\n",
        "            total_chars = 0\n",
        "        else:\n",
        "            data = data + \" \" + words[i]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pedkkmIjmnQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert the Data into Pandas DataFrame\n",
        "\n",
        "dict_ = {'paper_id': [], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\n",
        "for idx, entry in enumerate(all_json):\n",
        "    if idx % (len(all_json) // 10) == 0:\n",
        "        print(f'Processing index: {idx} of {len(all_json)}')\n",
        "    content = FileReader(entry)\n",
        "    \n",
        "    # get metadata information\n",
        "    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
        "    # no metadata, skip this paper\n",
        "    if len(meta_data) == 0:\n",
        "        continue\n",
        "    \n",
        "    dict_['paper_id'].append(content.paper_id)\n",
        "    dict_['abstract'].append(content.abstract)\n",
        "    dict_['body_text'].append(content.body_text)\n",
        "    \n",
        "    # also create a column for the summary of abstract to be used in a plot\n",
        "    if len(content.abstract) == 0: \n",
        "        # no abstract provided\n",
        "        dict_['abstract_summary'].append(\"Not provided.\")\n",
        "    elif len(content.abstract.split(' ')) > 100:\n",
        "        # abstract provided is too long for plot, take first 300 words append with ...\n",
        "        info = content.abstract.split(' ')[:100]\n",
        "        summary = get_breaks(' '.join(info), 40)\n",
        "        dict_['abstract_summary'].append(summary + \"...\")\n",
        "    else:\n",
        "        # abstract is short enough\n",
        "        summary = get_breaks(content.abstract, 40)\n",
        "        dict_['abstract_summary'].append(summary)\n",
        "        \n",
        "    # get metadata information\n",
        "    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
        "    \n",
        "    try:\n",
        "        # if more than one author\n",
        "        authors = meta_data['authors'].values[0].split(';')\n",
        "        if len(authors) > 2:\n",
        "            # more than 2 authors, may be problem when plotting, so take first 2 append with ...\n",
        "            dict_['authors'].append(\". \".join(authors[:2]) + \"...\")\n",
        "        else:\n",
        "            # authors will fit in plot\n",
        "            dict_['authors'].append(\". \".join(authors))\n",
        "    except Exception as e:\n",
        "        # if only one author - or Null valie\n",
        "        dict_['authors'].append(meta_data['authors'].values[0])\n",
        "    \n",
        "    # add the title information, add breaks when needed\n",
        "    try:\n",
        "        title = get_breaks(meta_data['title'].values[0], 40)\n",
        "        dict_['title'].append(title)\n",
        "    # if title was not provided\n",
        "    except Exception as e:\n",
        "        dict_['title'].append(meta_data['title'].values[0])\n",
        "    \n",
        "    # add the journal information\n",
        "    dict_['journal'].append(meta_data['journal'].values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cngsP3SXm4-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT3K2rZim5BW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_covid = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\n",
        "df_covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttFjtNpSm48Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_ = None\n",
        "#Data Pre-Processing/Cleaning\n",
        "\n",
        "## Adding word count columns for both abstract and body_text\n",
        "df_covid['abstract_word_count'] = df_covid['abstract'].apply(lambda x: len(x.strip().split()))\n",
        "df_covid['body_word_count'] = df_covid['body_text'].apply(lambda x: len(x.strip().split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJJhCrPxm47w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Remove Duplicates\n",
        "df_covid.drop_duplicates(['abstract', 'body_text'], inplace=True)\n",
        "## Remove NA's from data\n",
        "df_covid.dropna(inplace=True)\n",
        "df_covid.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmoSTfhbnGq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Taking only 12000 articles for analysis:\n",
        "df_covid = df_covid.head(12000)\n",
        "## Remove punctuation from each text:\n",
        "df_covid['body_text'] = df_covid['body_text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
        "df_covid['abstract'] = df_covid['abstract'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
        "df_covid['title'] = df_covid['title'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZTyF81UnGwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Convert each text to lower case:\n",
        "def lower_case(input_str):\n",
        "    input_str = input_str.lower()\n",
        "    return input_str\n",
        "\n",
        "df_covid['body_text'] = df_covid['body_text'].apply(lambda x: lower_case(x))\n",
        "df_covid['abstract'] = df_covid['abstract'].apply(lambda x: lower_case(x))\n",
        "df_covid['title'] = df_covid['title'].apply(lambda x: lower_case(x))\n",
        "## Considering body of articles only:\n",
        "text = df_covid[[\"title\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0hIxjMbnG0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Converting text dataframe into array:\n",
        "text_arr = text.stack().tolist()\n",
        "len(text_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL_Wr2-CnGuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Considering only 500 articles for analysis:\n",
        "require_text = text_arr[:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "solCFApgnGow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8SLdVqynY0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sentence Tokenization\n",
        "\n",
        "## Using Spacy module for Sentence Tokenization:\n",
        "sentences = []\n",
        "for body in tqdm(require_text):\n",
        "    doc = nlp(body)\n",
        "    for i in doc.sents:\n",
        "        if len(i)>10:\n",
        "            ## Taking those sentences only which have length more than 10\n",
        "            sentences.append(i.string.strip())\n",
        "\n",
        "print(len(sentences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi2TTGW_nY9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading Flair & Elmo Contextual Biomedical Embeddings\n",
        "\n",
        "## Creating Document Pool Embeddings using Stacked of PooledFlairEmbeddings('pubmed-forward'), PooledFlairEmbeddings('pubmed-backward') & ELMoEmbeddings('pubmed')\n",
        "document_embeddings = DocumentPoolEmbeddings([PooledFlairEmbeddings('pubmed-forward'),\n",
        "                                             PooledFlairEmbeddings('pubmed-backward'),\n",
        "                                             ELMoEmbeddings('pubmed')],\n",
        "                                             pooling='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aub4zy7nY54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Getting sentence embeddings for each sentence and storing those into flair_elmo_ls:\n",
        "flair_elmo_ls = []\n",
        "\n",
        "for _sent in tqdm(sentences):\n",
        "    example = Sentence(_sent)\n",
        "    document_embeddings.embed(example)\n",
        "    flair_elmo_ls.append(example.get_embedding())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtZcQQElnYxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Converting embeddings into numpy array :\n",
        "flair_elmo_arr = [emb.cpu().detach().numpy() for emb in flair_elmo_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvxmsL-nnnAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dimensionality Reduction with t-SNE\n",
        "\n",
        "tsne = TSNE(verbose=1, perplexity=5)\n",
        "X_embedded = tsne.fit_transform(flair_elmo_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyaxsenjnnHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Clusters (K-Means) of Sentence Embeddings\n",
        "\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "k = 20\n",
        "kmeans = MiniBatchKMeans(n_clusters=k)\n",
        "y_pred = kmeans.fit_predict(flair_elmo_arr)\n",
        "y = y_pred\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import random \n",
        "\n",
        "# sns settings\n",
        "sns.set(rc={'figure.figsize':(15,15)})\n",
        "\n",
        "# let's shuffle the list so distinct colors stay next to each other\n",
        "palette = sns.hls_palette(20, l=.4, s=.9)\n",
        "random.shuffle(palette)\n",
        "\n",
        "# plot\n",
        "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full', palette=palette)\n",
        "plt.title(\"t-SNE Covid-19 Articles - Clustered (K-Means) - Flair & Elmo Biomedical Embeddings\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CG3e5lknnEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_notebook()\n",
        "y_labels = y_pred\n",
        "\n",
        "# data sources\n",
        "source = ColumnDataSource(data=dict(\n",
        "    x= X_embedded[:,0], \n",
        "    y= X_embedded[:,1],\n",
        "    x_backup = X_embedded[:,0],\n",
        "    y_backup = X_embedded[:,1],\n",
        "    desc= y_labels, \n",
        "    titles= df_covid['title'],\n",
        "    authors = df_covid['authors'],\n",
        "    journal = df_covid['journal'],\n",
        "    abstract = df_covid['abstract_summary'],\n",
        "    labels = [\"C-\" + str(x) for x in y_labels]\n",
        "    ))\n",
        "\n",
        "# hover over information\n",
        "hover = HoverTool(tooltips=[\n",
        "    (\"Title\", \"@titles{safe}\"),\n",
        "    (\"Author(s)\", \"@authors\"),\n",
        "    (\"Journal\", \"@journal\"),\n",
        "    (\"Abstract\", \"@abstract{safe}\"),\n",
        "],\n",
        "                 point_policy=\"follow_mouse\")\n",
        "\n",
        "# map colors\n",
        "mapper = linear_cmap(field_name='desc', \n",
        "                     palette=Category20[20],\n",
        "                     low=min(y_labels) ,high=max(y_labels))\n",
        "\n",
        "# prepare the figure\n",
        "p = figure(plot_width=800, plot_height=800, \n",
        "           tools=[hover, 'pan', 'wheel_zoom', 'box_zoom', 'reset'], \n",
        "           title=\"t-SNE Covid-19 Articles, Clustered(K-Means), Flair & Elmo Biomedical Embeddings\", \n",
        "           toolbar_location=\"right\")\n",
        "\n",
        "# plot\n",
        "p.scatter('x', 'y', size=5, \n",
        "          source=source,\n",
        "          fill_color=mapper,\n",
        "          line_alpha=0.3,\n",
        "          line_color=\"black\",\n",
        "          legend = 'labels')\n",
        "\n",
        "# add callback to control \n",
        "callback = CustomJS(args=dict(p=p, source=source), code=\"\"\"\n",
        "            \n",
        "            var radio_value = cb_obj.active;\n",
        "            var data = source.data; \n",
        "            \n",
        "            x = data['x'];\n",
        "            y = data['y'];\n",
        "            \n",
        "            x_backup = data['x_backup'];\n",
        "            y_backup = data['y_backup'];\n",
        "            \n",
        "            labels = data['desc'];\n",
        "            \n",
        "            if (radio_value == '20') {\n",
        "                for (i = 0; i < x.length; i++) {\n",
        "                    x[i] = x_backup[i];\n",
        "                    y[i] = y_backup[i];\n",
        "                }\n",
        "            }\n",
        "            else {\n",
        "                for (i = 0; i < x.length; i++) {\n",
        "                    if(labels[i] == radio_value) {\n",
        "                        x[i] = x_backup[i];\n",
        "                        y[i] = y_backup[i];\n",
        "                    } else {\n",
        "                        x[i] = undefined;\n",
        "                        y[i] = undefined;\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "\n",
        "\n",
        "        source.change.emit();\n",
        "        \"\"\")\n",
        "\n",
        "# callback for searchbar\n",
        "keyword_callback = CustomJS(args=dict(p=p, source=source), code=\"\"\"\n",
        "            \n",
        "            var text_value = cb_obj.value;\n",
        "            var data = source.data; \n",
        "            \n",
        "            x = data['x'];\n",
        "            y = data['y'];\n",
        "            \n",
        "            x_backup = data['x_backup'];\n",
        "            y_backup = data['y_backup'];\n",
        "            \n",
        "            abstract = data['abstract'];\n",
        "            titles = data['titles'];\n",
        "            authors = data['authors'];\n",
        "            journal = data['journal'];\n",
        "\n",
        "            for (i = 0; i < x.length; i++) {\n",
        "                if(abstract[i].includes(text_value) || \n",
        "                   titles[i].includes(text_value) || \n",
        "                   authors[i].includes(text_value) || \n",
        "                   journal[i].includes(text_value)) {\n",
        "                    x[i] = x_backup[i];\n",
        "                    y[i] = y_backup[i];\n",
        "                } else {\n",
        "                    x[i] = undefined;\n",
        "                    y[i] = undefined;\n",
        "                }\n",
        "            }\n",
        "            \n",
        "\n",
        "\n",
        "        source.change.emit();\n",
        "        \"\"\")\n",
        "\n",
        "# option\n",
        "option = RadioButtonGroup(labels=[\"C-0\", \"C-1\", \"C-2\",\n",
        "                                  \"C-3\", \"C-4\", \"C-5\",\n",
        "                                  \"C-6\", \"C-7\", \"C-8\",\n",
        "                                  \"C-9\", \"C-10\", \"C-11\",\n",
        "                                  \"C-12\", \"C-13\", \"C-14\",\n",
        "                                  \"C-15\", \"C-16\", \"C-17\",\n",
        "                                  \"C-18\", \"C-19\", \"All\"], \n",
        "                          active=20, callback=callback)\n",
        "\n",
        "# search box\n",
        "keyword = TextInput(title=\"Search:\", callback=keyword_callback)\n",
        "\n",
        "#header\n",
        "header = Div(text=\"\"\"<h1>COVID-19 Articles Cluster</h1>\"\"\")\n",
        "\n",
        "# show\n",
        "show(column(header, widgetbox(option, keyword),p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWqjqI3mnm-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Semantic Search\n",
        "\n",
        "def get_similarity(search_string, results_returned = 3):\n",
        "    example_text = Sentence(search_string)\n",
        "    document_embeddings.embed(example_text)\n",
        "    search_vect = example_text.get_embedding()\n",
        "    search_vect = search_vect.cpu().detach().numpy()\n",
        "    cosine_similarities = pd.Series(cosine_similarity([search_vect], flair_elmo_arr).flatten())\n",
        "    output =\"\"\n",
        "    for i,j in cosine_similarities.nlargest(int(results_returned)).iteritems():\n",
        "        output +='<p style=\"font-family:verdana; font-size:110%;\"> '\n",
        "        for i in sentences[i].split():\n",
        "            if i.lower() in search_string:\n",
        "                output += \" <b>\"+str(i)+\"</b>\"\n",
        "            else:\n",
        "                output += \" \"+str(i)\n",
        "        output += \"</p><hr>\"\n",
        "\n",
        "    output = '<h3>Results:</h3>'+output\n",
        "    display(HTML(output))\n",
        "\n",
        "text = widgets.Text(\n",
        "    value='virus genetics, origin, and evolution',\n",
        "    placeholder='Paste ticket description here!',\n",
        "    description='Query:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='50%', height='50px')\n",
        ")\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def callback(_):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        # what happens when we press the button\n",
        "        printmd(\"**<font color=orange> -------------------------------------------------------------------------------------------------------- </font>**\")        \n",
        "        printmd(f\"**<font color=blue>Semantic Search has Started </font>**\")\n",
        "        get_similarity(text.value)\n",
        "        printmd(\"**<font color=orange> -------------------------------------------------------------------------------------------------------- </font>**\")        \n",
        "\n",
        "text.on_submit(callback)\n",
        "# displaying button and its output together\n",
        "widgets.VBox([text, out])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5qGGCLLoFG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#An End-To-End Closed Domain Question Answering System (CdQA)\n",
        "\n",
        "# Install an End-To-End Closed Domain Question Answering System\n",
        "!pip install cdqa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guIhi1ktoFFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load Cdqa Utilities:\n",
        "from ast import literal_eval\n",
        "\n",
        "from cdqa.utils.filters import filter_paragraphs\n",
        "from cdqa.pipeline import QAPipeline\n",
        "from cdqa.utils.download import download_model\n",
        "## Download BERT Squad 1.1 Pretrained Q&A Model\n",
        "download_model(model='bert-squad_1.1', dir='./models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w9g19AUoTkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Converting body_text into different paragraphs :\n",
        "df_covid[\"paragraphs\"] = [x.split('\\n') for x in df_covid[\"body_text\"]]\n",
        "df = filter_paragraphs(df_covid)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eORANEp7oUZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cdqa_pipeline = QAPipeline(reader='./models/bert_qa.joblib')\n",
        "cdqa_pipeline.fit_retriever(df=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx15d8wUoXs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX0mOYNXoXxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cdqa_prediction(x):\n",
        "    prediction = cdqa_pipeline.predict(x)\n",
        "    question = '<h3>Question:</h3>'+x\n",
        "    answer = '<h3>Answer:</h3>'+prediction[0]\n",
        "    title = '<h3>Title:</h3>'+prediction[1]    \n",
        "    paragraph = '<h3>Paragraph:</h3>'+prediction[2]    \n",
        "    \n",
        "    display(HTML(question))\n",
        "    display(HTML(answer))\n",
        "    display(HTML(title))\n",
        "    display(HTML(paragraph))\n",
        "text = widgets.Text(\n",
        "    value='What do we know about diagnostics and surveillance?',\n",
        "    placeholder='Paste ticket description here!',\n",
        "    description='Question:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='50%', height='50px')\n",
        ")\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def callback(_):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        # what happens when we press the button\n",
        "        printmd(\"**<font color=orange> ------------------------------------------------------------------------------------------------------------------------------- </font>**\")        \n",
        "        printmd(f\"**<font color=blue>COVID-19 (Question & Answering System)</font>**\")\n",
        "        get_cdqa_prediction(text.value)\n",
        "        printmd(\"**<font color=orange> ------------------------------------------------------------------------------------------------------------------------------- </font>**\")        \n",
        "\n",
        "text.on_submit(callback)\n",
        "# displaying button and its output together\n",
        "widgets.VBox([text, out])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR99nflqoXq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}