{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_info_retrieval_homework_unrun.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYWPdoAKfyYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data_path = \"../input/ted_main.csv\"\n",
        "data = pd.read_csv(data_path)\n",
        "data.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbO44enagC5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "descriptions = [tokenizer.tokenize(description.lower()) for description in data[\"description\"]]\n",
        "print(descriptions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfpQyLiLgDe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting texts to a Bag-of-Words format\n",
        "from gensim import corpora\n",
        "#Here we're gonna use the default Dictionary function (but you can implement your own converter if you wish).\n",
        "\n",
        "corpora_dict = corpora.Dictionary(descriptions)\n",
        "print(corpora_dict.token2id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEZhMKXWgJHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(corpora_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU8qOmxPgJDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now let's look at the BoW representation of an arbitrary sentense.\n",
        "\n",
        "new_doc = \"Save trees in sake of ecology!\"\n",
        "new_vec = corpora_dict.doc2bow(tokenizer.tokenize(new_doc.lower()))\n",
        "print(new_vec)\n",
        "\n",
        "for word_id, _ in new_vec:\n",
        "    print(corpora_dict.id2token[word_id], end=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRYN9UJWgXsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [corpora_dict.doc2bow(text) for text in descriptions]\n",
        "print(corpus[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvF8XBU6gXnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now it's time to make a simple search machine.\n",
        "\n",
        "#BoW search machine\n",
        "\n",
        "from gensim import similarities\n",
        "index_bow = similarities.SparseMatrixSimilarity(corpus, num_features=len(corpora_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpjltlYIgJB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search(index, query, top_n=5, prints=False):\n",
        "    \"\"\"\n",
        "    This function searches the most similar texts to the query.\n",
        "        :param index: gensim.similarities object\n",
        "        :param query: a string\n",
        "        :param top_n: how many variants it returns\n",
        "        :param prints: if True returns the results, otherwise prints the results\n",
        "        :returns: a list of tuples (matched_document_index, similarity_value)\n",
        "    \"\"\"\n",
        "    # getting a BoW vector\n",
        "    bow_vec = corpora_dict.doc2bow(query.lower().split())\n",
        "    similarities = index[bow_vec]  # get similarities between the query and all index documents\n",
        "    similarities = [(x, i) for i, x in enumerate(similarities)]\n",
        "    similarities.sort(key=lambda elem: -elem[0])  # sorting by similarity_value in decreasing order\n",
        "    res = []\n",
        "    if prints:\n",
        "        print(f\"{query}\\n\")\n",
        "    for result in similarities[:top_n]:\n",
        "        if prints:\n",
        "            print(f\"{data['description'][result[1]]} \\t {result[0]}\\n\")\n",
        "        else:\n",
        "            res.append((result[1], result[0]))\n",
        "    if not prints:\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULWnFIVDgr_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search(index_bow, \"education system\", prints=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZDtdIyHgwCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search(index_bow, \"healthy food\", prints=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aw-aDnDgwrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#search texts by citations\n",
        "search(index_bow, \"In an emotionally charged talk\", prints=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKkSf-L5gzbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#searching by an annotation\n",
        "search(index_bow, \"Majora Carter: Greening the ghetto\", prints=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHJmf3v7gzSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Seems like our tagret document is not in top-5 results.\n",
        "\n",
        "# On the next step, we will make more 'smart' model, TF-IDF model."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiNLx84phGCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import TfidfModel\n",
        "model_tfidf = TfidfModel(corpus)\n",
        "vector = model_tfidf[corpus[0]]\n",
        "print(vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NjsnTophKXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_tfidf = model_tfidf[corpus]\n",
        "index_tfidf = similarities.SparseMatrixSimilarity(corpus_tfidf, num_features=len(corpora_dict))\n",
        "search(index_tfidf, \"Majora Carter: Greening the ghetto\", prints=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxcC_0e6hKSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[data[\"main_speaker\"] == \"Majora Carter\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvfDcRBzhQ1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m6YnNXyhUz7",
        "colab_type": "text"
      },
      "source": [
        "Now, it's time to use dense vectors instead of sparse ones.\n",
        "\n",
        "Doing SVD / LSA with your own hands\n",
        "This approach has a lot of names but it's main idea is quite simple: we try to approximate out source matrix by matrix of a lower rank. In this task, we will use original BoW matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTkMNt78hQ0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "i_inds = []\n",
        "j_inds = []\n",
        "data_ij_values = []\n",
        "\n",
        "for i_ind, sparse_doc in enumerate(corpus):\n",
        "    for j_ind, data_ij in sparse_doc:\n",
        "        i_inds.append(i_ind)\n",
        "        j_inds.append(j_ind)\n",
        "        data_ij_values.append(data_ij)\n",
        "sparse_corpus = coo_matrix((data_ij_values, (i_inds, j_inds)))\n",
        "full_corpus = sparse_corpus.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAcWMD_5hY1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPDlTV54hY7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sparse_corpus and fullcorpus are matrices with sizes $N{documents} \\times V where V = len(vocabulary)$\n",
        "\n",
        "sparse_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XytGj68hYzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omaulNEAhgwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7KOpJafhg5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We want to work with words as rows, so we have to transpose the matrix."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNrHtpsGhg0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.linalg as la\n",
        "full_corpus = full_corpus.T\n",
        "U, s, Vt = la.svd(full_corpus)\n",
        "print(U.shape, s.shape, Vt.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKyh_W0khguE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now we can choose how many singular values (s) we will take to approximate an original matrix."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PPRUvzchp6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNAhCemShqG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(np.arange(1, s.shape[0] + 1), s, label=\"singular values\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkeXqBYuhp-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rank_svd = 250\n",
        "\n",
        "U_trunced = U[:, :rank_svd]\n",
        "s_trunced = s[:rank_svd]\n",
        "Vt_trunced = Vt[:rank_svd, :]\n",
        "print(U_trunced.shape, s_trunced.shape, Vt_trunced.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czs9o1whhp9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_lsa = U_trunced.dot(np.diag(s_trunced)).dot(Vt_trunced)\n",
        "corpus_lsa.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ1Ke2Rehp4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_lsa[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcJkjYyUh1OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGtiXwVZh4V2",
        "colab_type": "text"
      },
      "source": [
        "Here you can run experiments on word similarity measurement.\n",
        "\n",
        "Back to documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMwDT4Q4h1Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_lsa = corpus_lsa.T\n",
        "index_lsa_bow = similarities.MatrixSimilarity(corpus_lsa, num_features=len(corpora_dict))\n",
        "search(index_lsa_bow, \"healthy food\", prints=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbADucCKh1Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe0hMtuDiBKz",
        "colab_type": "text"
      },
      "source": [
        "LSI\n",
        "\n",
        "It is almost the same that we did in the previous section but this time we will used a built-in function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW5VJfBAh1SP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import LsiModel\n",
        "model_lsi = LsiModel(corpus, id2word=corpora_dict.id2token, num_topics=rank_svd)\n",
        "model_lsi.print_topics(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yCfEvYph1MQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(rank_svd):\n",
        "    print(i, model_lsi.projection.s[i], s_trunced[i], np.allclose(model_lsi.projection.s[i], s_trunced[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtMYalcbiQOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5XyAbtSiQR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_lsi = model_lsi[corpus]\n",
        "len(corpus_lsi), len(corpus_lsi[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92vm-2SoiQMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_lsi_bow = similarities.MatrixSimilarity(corpus_lsi, num_features=len(corpora_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gsc-ecbiT5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3xAhkJviT86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search(index_lsi_bow, \"education system\", prints=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IpfgmtTiT3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search(index_lsi_bow, \"healthy food\", prints=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOeu0lVdiZew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-8704Tijuy",
        "colab_type": "text"
      },
      "source": [
        "Can you explain why do we have zeros here?\n",
        "\n",
        "Homework (10 points)\n",
        "\n",
        "Your own Dictionary (2 points)\n",
        "\n",
        "Implement a class analogous to corpora.Dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XryXmjKPiZkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDictionary():\n",
        "    def __init__(tokenized_texts):\n",
        "        self.token2id = dict()\n",
        "        self.id2token = dict()\n",
        "        # YOUR CODE HERE    \n",
        "    def doc2bow(tokenized_text):\n",
        "        # YOUR CODE HERE\n",
        "        return # YOUR CODE HERE\n",
        "test_corpus = [['hello', 'world'], ['hello']]\n",
        "my_dictionary = MyDictionary(test_corpus)\n",
        "for word in {'hello', 'world'}:\n",
        "    assert word in my_dictionary.token2id\n",
        "    assert my_dictionary.token2id[word] = my_dictionary.id2token[my_dictionary.token2id[word]]\n",
        "my_test_corpus_bow = [my_dictionary.doc2bow(text) for text in test_corpus] \n",
        "test_corpus_bow = [[(0, 1), (1, 1)], [(0, 1)]]\n",
        "assert my_test_corpus_bow == test_corpus_bow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdYSsYXri2uP",
        "colab_type": "text"
      },
      "source": [
        "Deleting stopwords (4 points)\n",
        "In this task, you will clear our text corpur from stopwords and non-words like ',', '!)' etc. After that, build a new BoW and TF-IDF models. Make several queries to old and new systems and compare tre results. Did deleting stopwords really increased a quality of the search?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXSrsmgViZcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# You may need regular expressions to check tokens on being real 'words'\n",
        "import re\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "clean_corpus = [] # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XyYZY0Ui6hQ",
        "colab_type": "text"
      },
      "source": [
        "Visualizing word embeddings (4 points)\n",
        "Given the example of visualizing BoW vectors on a 2D-plain, plot the same graphs for TF-IDF model without stopwords. Does distributional hipothesis work here? Explain your answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okLvyHoEi6-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    if isinstance(color, str): color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: pl.show(fig)\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4bFtw9Yi-j6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoMfIbVTi-nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "\n",
        "word_vectors_pca = PCA(n_components=2, random_state=4117).fit_transform(full_corpus)  # insert TF-IDF vectors here\n",
        "word_vectors_pca = preprocessing.scale(word_vectors_pca)\n",
        "period = 50  # you can use 10 or 25 if it's ok for your computer\n",
        "\n",
        "words = [corpora_dict.id2token[i] for i in range(len(corpora_dict))][::period]\n",
        "draw_vectors(word_vectors_pca[:, 0][::period], word_vectors_pca[:, 1][::period], token=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KyIBW2ki-hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The other way of projecting high-dimentional data on a 2D plain is t-SNE.\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "word_tsne = TSNE(n_components=2, verbose=100).fit_transform(full_corpus[::period])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICKJV7VJjFIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}